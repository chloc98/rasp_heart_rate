import numpy as np
import tensorflow as tf
import pandas as pd
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten
from sklearn.preprocessing import MinMaxScaler

# Mount drive và đọc file excel vào df
from google.colab import drive
drive.mount('/content/drive')
df = pd.read_excel("/content/drive/MyDrive/Adidas US Sales Datasets.xlsx")

# In ra tất cả các tên cột trong DataFrame
print(df.columns)

# Loại bỏ các dòng có giá trị không hợp lệ
df = df[pd.to_datetime(df['Unnamed: 3'], errors='coerce').notnull()]
# Chuyển đổi cột ngày sang dạng thời gian (datetime) và chuyển đổi thành timestamp
df.loc[:, 'Unnamed: 3'] = pd.to_datetime(df['Unnamed: 3'])
df.loc[:, 'Unnamed: 3'] = df['Unnamed: 3'].apply(lambda x: x.timestamp())

# Giả sử df là DataFrame chứa dữ liệu doanh thu
X_train = df['Unnamed: 3'].values.reshape(-1, 1)  # Sử dụng cột ngày làm đầu vào
y_train = df['Unnamed: 10'].values.reshape(-1, 1)  # Sử dụng cột doanh thu làm đầu ra

from sklearn.preprocessing import MinMaxScaler

# Khởi tạo scaler và chuẩn hóa dữ liệu
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
y_train_scaled = scaler_y.fit_transform(y_train)

# Tạo dữ liệu giả
X = np.random.rand(2000, 1)
y = np.random.randint(0, 2, size=(2000, 1))
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
batch_size = 64
noise = np.random.normal(0, 1, (batch_size, 100))

# Tạo generator
latent_dim = X_train.shape[-1] # latent_dim = 1

def build_generator(latent_dim, output_dim):
    model = Sequential()
    model.add(Dense(256, input_dim=latent_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(1024))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(output_dim, activation='tanh'))
    return model

output_dim = 1
generator = build_generator(latent_dim, output_dim)

input_dim = 1
def build_discriminator(input_dim):
    model = Sequential()
    model.add(Dense(64, input_dim=input_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(1, activation='sigmoid'))
    return model

discriminator = build_discriminator(input_dim=input_dim)

X_train.shape # (mẫu, đặc trưng)
# Giả sử kết quả là (2000,1)

# Huấn luyện discriminator
epochs = 10
batch_size = 128
discriminator.trainable = True
discriminator.compile(loss='binary_crossentropy', optimizer='adam',
                      metrics=['accuracy'])
discriminator.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)

# Tạo và compile mô hình GAN
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    model.compile(loss='binary_crossentropy', optimizer='adam')
    model.summary()
    return model
